{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-MQiWsEofgp"
      },
      "outputs": [],
      "source": [
        "import os, json, random\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "BASE = \"/content/drive/MyDrive/cs-senti\"   # adjust if your mount path is different\n",
        "DATA = f\"{BASE}/data\"\n",
        "OUT  = f\"{BASE}/chang\"\n",
        "os.makedirs(OUT, exist_ok=True)\n",
        "os.makedirs(f\"{OUT}/checkpoints\", exist_ok=True)\n",
        "os.makedirs(f\"{OUT}/samples\", exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets\n"
      ],
      "metadata": {
        "id": "MG-P03mNu-Cx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9OMqduLsFpKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# load the full dataset from HF\n",
        "ds = load_dataset(\"HeshamHaroon/ArzEn-MultiGenre\")\n",
        "ds\n"
      ],
      "metadata": {
        "id": "kFvgavgpvBdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show first 5 examples from the main split (often 'train')\n",
        "for i in range(5):\n",
        "    print(ds[\"train\"][i])\n"
      ],
      "metadata": {
        "id": "zGALt_XLvF8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import os, json, re\n",
        "\n",
        "BASE = \"/content/drive/MyDrive/cs-senti\"\n",
        "DATA = f\"{BASE}/data\"\n",
        "os.makedirs(DATA, exist_ok=True)\n",
        "\n",
        "# 1) load HF dataset\n",
        "ds = load_dataset(\"HeshamHaroon/ArzEn-MultiGenre\")[\"train\"]\n",
        "print(\"rows:\", len(ds))\n",
        "\n",
        "# regexes\n",
        "ARABIC_RE  = re.compile(r\"[\\u0600-\\u06FF]\")\n",
        "LATIN_RE   = re.compile(r\"[A-Za-z]\")\n",
        "\n",
        "# clean RTL marks like \\u202b \\u202c\n",
        "def strip_rtl(s: str) -> str:\n",
        "    return s.replace(\"\\u202b\", \"\").replace(\"\\u202c\", \"\").strip()\n",
        "\n",
        "# open outputs\n",
        "mono_ar_out = open(f\"{DATA}/amg_ar_mono.jsonl\", \"w\", encoding=\"utf-8\")\n",
        "mono_en_out = open(f\"{DATA}/amg_en_mono.jsonl\", \"w\", encoding=\"utf-8\")\n",
        "cs_ar_out   = open(f\"{DATA}/amg_cs_from_amg.jsonl\", \"w\", encoding=\"utf-8\")\n",
        "\n",
        "mono_count = 0\n",
        "cs_count = 0\n",
        "skip_none = 0\n",
        "\n",
        "for row in ds:\n",
        "    ar_txt = strip_rtl(row.get(\"EGY\", \"\") or \"\")\n",
        "    en_txt = row.get(\"ENG\", \"\")\n",
        "    if en_txt is None:\n",
        "        skip_none += 1\n",
        "        continue\n",
        "    en_txt = en_txt.strip()\n",
        "    if not ar_txt or not en_txt:\n",
        "        continue\n",
        "\n",
        "    # must have Arabic\n",
        "    has_ar = bool(ARABIC_RE.search(ar_txt))\n",
        "    has_lat = bool(LATIN_RE.search(ar_txt))\n",
        "\n",
        "    if has_ar and not has_lat:\n",
        "        # pure/mostly Arabic (monolingual host)\n",
        "        mono_ar_out.write(json.dumps({\"text\": ar_txt}, ensure_ascii=False) + \"\\n\")\n",
        "        mono_en_out.write(json.dumps({\"text\": en_txt}, ensure_ascii=False) + \"\\n\")\n",
        "        mono_count += 1\n",
        "    else:\n",
        "        # keep CS examples separate\n",
        "        cs_ar_out.write(json.dumps({\"text\": ar_txt}, ensure_ascii=False) + \"\\n\")\n",
        "        cs_count += 1\n",
        "\n",
        "mono_ar_out.close()\n",
        "mono_en_out.close()\n",
        "cs_ar_out.close()\n",
        "\n",
        "print(\"mono host rows:\", mono_count)\n",
        "print(\"cs-ish rows  :\", cs_count)\n",
        "print(\"skipped ENG=None:\", skip_none)\n",
        "print(\"saved to:\", f\"{DATA}/amg_ar_mono.jsonl\", f\"{DATA}/amg_en_mono.jsonl\", f\"{DATA}/amg_cs_from_amg.jsonl\")\n"
      ],
      "metadata": {
        "id": "IMkTi87nvuGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random, json\n",
        "\n",
        "ar_path = f\"{DATA}/amg_ar_mono.jsonl\"\n",
        "en_path = f\"{DATA}/amg_en_mono.jsonl\"\n",
        "\n",
        "with open(ar_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    ar_lines = [json.loads(l)[\"text\"] for l in f]\n",
        "with open(en_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    en_lines = [json.loads(l)[\"text\"] for l in f]\n",
        "\n",
        "for i in random.sample(range(min(len(ar_lines), len(en_lines))), 5):\n",
        "    print(\"=\"*70)\n",
        "    print(\"AR:\", ar_lines[i])\n",
        "    print(\"EN:\", en_lines[i])\n"
      ],
      "metadata": {
        "id": "VuKOyDwYwMeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, random\n",
        "from pathlib import Path\n",
        "import torch\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "BASE = \"/content/drive/MyDrive/cs-senti\"   # change if your mount is different\n",
        "DATA = f\"{BASE}/data\"\n",
        "OUT  = f\"{BASE}/chang\"\n",
        "os.makedirs(OUT, exist_ok=True)\n",
        "os.makedirs(f\"{OUT}/checkpoints\", exist_ok=True)\n",
        "os.makedirs(f\"{OUT}/samples\", exist_ok=True)\n",
        "\n",
        "def read_jsonl(path, n=None):\n",
        "    out = []\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for i, line in enumerate(f):\n",
        "            if not line.strip():\n",
        "                continue\n",
        "            obj = json.loads(line)\n",
        "            txt = obj.get(\"text\", \"\").strip()\n",
        "            if txt:\n",
        "                out.append(txt)\n",
        "            if n is not None and len(out) >= n:\n",
        "                break\n",
        "    return out\n",
        "\n",
        "# 1) host = cleaned AMG monolingual arabic\n",
        "amg_ar_path = f\"{DATA}/amg_ar_mono.jsonl\"   # <--- the file we just made from HF\n",
        "HOST_TEXTS  = read_jsonl(amg_ar_path)\n",
        "print(\"HOST_TEXTS:\", len(HOST_TEXTS))\n",
        "\n",
        "# 2) parallel for lexicon (same filtered subset)\n",
        "amg_en_path = f\"{DATA}/amg_en_mono.jsonl\"\n",
        "AMG_AR = read_jsonl(amg_ar_path)\n",
        "AMG_EN = read_jsonl(amg_en_path)\n",
        "\n",
        "# clip to overlap to stay aligned\n",
        "min_len = min(len(AMG_AR), len(AMG_EN))\n",
        "AMG_AR  = AMG_AR[:min_len]\n",
        "AMG_EN  = AMG_EN[:min_len]\n",
        "print(\"AMG_AR lines:\", len(AMG_AR))\n",
        "print(\"AMG_EN lines:\", len(AMG_EN))\n",
        "print(\"Using parallel overlap:\", min_len)\n",
        "\n",
        "# 3) real CS pools\n",
        "REAL_CS_TEXTS = []\n",
        "\n",
        "# 3a) AMG human-labeled CS\n",
        "amg_cs_human_path = f\"{DATA}/amg_cs_human_labels.jsonl\"\n",
        "if os.path.exists(amg_cs_human_path):\n",
        "    AMG_CS_TXT = read_jsonl(amg_cs_human_path)\n",
        "    REAL_CS_TEXTS += AMG_CS_TXT\n",
        "else:\n",
        "    AMG_CS_TXT = []\n",
        "\n",
        "# 3b) CS we auto-split from the HF AMG\n",
        "amg_cs_auto_path = f\"{DATA}/amg_cs_from_amg.jsonl\"\n",
        "if os.path.exists(amg_cs_auto_path):\n",
        "    REAL_CS_TEXTS += read_jsonl(amg_cs_auto_path)\n",
        "\n",
        "# 3c) EESA CS\n",
        "eesa_train_path = f\"{DATA}/eesa_train.jsonl\"\n",
        "if os.path.exists(eesa_train_path):\n",
        "    EESA_TXT = read_jsonl(eesa_train_path)\n",
        "    REAL_CS_TEXTS += EESA_TXT\n",
        "else:\n",
        "    EESA_TXT = []\n",
        "\n",
        "# 3d) MR CS\n",
        "mr_cs_path = f\"{DATA}/mr_cs.jsonl\"\n",
        "if os.path.exists(mr_cs_path):\n",
        "    MR_TEXTS = read_jsonl(mr_cs_path)\n",
        "    REAL_CS_TEXTS += MR_TEXTS\n",
        "else:\n",
        "    MR_TEXTS = []\n",
        "\n",
        "print(\"REAL_CS_TEXTS:\", len(REAL_CS_TEXTS))\n",
        "print(\"  AMG_CS_TXT (human):\", len(AMG_CS_TXT))\n",
        "print(\"  EESA_TXT           :\", len(EESA_TXT))\n",
        "print(\"  MR_TEXTS           :\", len(MR_TEXTS))\n",
        "\n",
        "# 4) quick preview to confirm\n",
        "print(\"\\n--- sample HOST (AMG AR mono) ---\")\n",
        "for t in random.sample(HOST_TEXTS, 3):\n",
        "    print(t)\n",
        "\n",
        "print(\"\\n--- sample parallel AR/EN ---\")\n",
        "for i in random.sample(range(len(AMG_AR)), 3):\n",
        "    print(\"=\"*70)\n",
        "    print(\"AR:\", AMG_AR[i])\n",
        "    print(\"EN:\", AMG_EN[i])\n",
        "\n",
        "print(\"\\n--- sample REAL CS ---\")\n",
        "for t in random.sample(REAL_CS_TEXTS, 3):\n",
        "    print(t)\n"
      ],
      "metadata": {
        "id": "2CrrcfgtsIJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import torch\n",
        "\n",
        "# we already have these from the previous cell\n",
        "# BASE, DATA, device, AMG_AR, AMG_EN are in scope\n",
        "\n",
        "# 1) build lexicon from parallel AMG\n",
        "ar2en = {}\n",
        "\n",
        "for ar_sent, en_sent in zip(AMG_AR, AMG_EN):\n",
        "    ar_toks = ar_sent.split()\n",
        "    en_toks = en_sent.split()\n",
        "    # keep it simple: only use sentences with same #tokens\n",
        "    if len(ar_toks) == len(en_toks):\n",
        "        for a, e in zip(ar_toks, en_toks):\n",
        "            a = a.strip()\n",
        "            e = e.strip().lower()\n",
        "            if a and (a not in ar2en):\n",
        "                ar2en[a] = e\n",
        "\n",
        "print(\"lexicon size (from AMG mono):\", len(ar2en))\n",
        "\n",
        "# 2) MT fallback (for words not in the lexicon)\n",
        "mt_name = \"Helsinki-NLP/opus-mt-ar-en\"\n",
        "mt_tok  = AutoTokenizer.from_pretrained(mt_name)\n",
        "mt_mod  = AutoModelForSeq2SeqLM.from_pretrained(mt_name).to(device)\n",
        "mt_mod.eval()\n",
        "\n",
        "@torch.no_grad()\n",
        "def mt_translate_one(token: str) -> str:\n",
        "    enc = mt_tok(token, return_tensors=\"pt\").to(device)\n",
        "    out = mt_mod.generate(**enc, max_length=16, num_beams=4)\n",
        "    txt = mt_tok.decode(out[0], skip_special_tokens=True)\n",
        "    # keep only the first word to stay token-like\n",
        "    return txt.split()[0] if txt else token\n",
        "\n",
        "def translate_token(ar_tok: str) -> str:\n",
        "    ar_tok = ar_tok.strip()\n",
        "    if ar_tok in ar2en:\n",
        "        return ar2en[ar_tok]\n",
        "    return mt_translate_one(ar_tok)\n",
        "\n",
        "# 3) quick sanity check\n",
        "test_words = [\n",
        "    \"Ø§Ù„Ø¬Ø§Ù…Ø¹Ø©\",\n",
        "    \"Ø§Ù„Ù…ÙˆØ¨Ø§ÙŠÙ„\",\n",
        "    \"Ø§Ù„Ø¨ÙŠØª\",\n",
        "    \"ÙÙ„ÙˆØ³\",\n",
        "    \"ÙƒÙ…Ø¨ÙŠÙˆØªØ±\",\n",
        "    \"Ø§Ù„Ø¹Ø±Ø¨ÙŠ\",\n",
        "]\n",
        "\n",
        "print(\"\\n--- sample translations ---\")\n",
        "for w in test_words:\n",
        "    print(f\"{w:>10s} -> {translate_token(w)}\")\n",
        "\n",
        "# 4) check on a real host sentence\n",
        "import random, regex as re\n",
        "AR_WORD = re.compile(r\"\\S+\")\n",
        "\n",
        "def tokenize_ar(text: str):\n",
        "    return AR_WORD.findall(text)\n",
        "\n",
        "sample_host = random.choice(HOST_TEXTS)\n",
        "toks = tokenize_ar(sample_host)\n",
        "translated = [translate_token(t) for t in toks]\n",
        "\n",
        "print(\"\\n--- sample host sentence ---\")\n",
        "print(\"AR:\", sample_host)\n",
        "print(\"EN-tokens (1-1):\", translated)\n"
      ],
      "metadata": {
        "id": "e8JyJLpOxe9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "fixing daatsets-  mr labelling"
      ],
      "metadata": {
        "id": "A5Hk19h_L8xN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "AMG CS SUBSET: we are checking the labels of the three annotators, and doing majority voting"
      ],
      "metadata": {
        "id": "yX51zTdk53cr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "path = \"/content/drive/MyDrive/cs-senti/labeling/amg_cs_final_adjudicated.csv\"\n",
        "df = pd.read_csv(path)\n",
        "print(df.columns.tolist())\n",
        "df.head(3)\n"
      ],
      "metadata": {
        "id": "48MsUI9fYMWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "BASE = Path(\"/content/drive/MyDrive/cs-senti\")\n",
        "\n",
        "# 1) original AMG-CS with text (from when you first labeled with XLM)\n",
        "orig_path  = BASE / \"labeling\" / \"amg_cs_pred_labelsXLM.csv\"\n",
        "# 2) final adjudicated labels (no text)\n",
        "final_path = BASE / \"labeling\" / \"amg_cs_final_adjudicated.csv\"\n",
        "# 3) output jsonl\n",
        "out_jsonl  = BASE / \"data\" / \"amg_cs_final_adjudicated.jsonl\"\n",
        "\n",
        "orig_df  = pd.read_csv(orig_path)          # has: id, text, eng, pred_label, ...\n",
        "final_df = pd.read_csv(final_path)         # has: id, final_label, ...\n",
        "\n",
        "# merge on id\n",
        "merged = orig_df.merge(final_df[[\"id\",\"final_label\"]], on=\"id\", how=\"inner\")\n",
        "\n",
        "print(\"merged shape:\", merged.shape)\n",
        "print(merged.head(3)[[\"id\",\"text\",\"final_label\"]])\n",
        "\n",
        "# write to jsonl\n",
        "with open(out_jsonl, \"w\", encoding=\"utf-8\") as f:\n",
        "    for _, row in merged.iterrows():\n",
        "        rec = {\n",
        "            \"text\": str(row[\"text\"]),\n",
        "            \"label\": str(row[\"final_label\"])\n",
        "        }\n",
        "        f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "print(\"âœ… wrote:\", out_jsonl)\n"
      ],
      "metadata": {
        "id": "Utyyz8IdXofZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Path to your new jsonl\n",
        "path = \"/content/drive/MyDrive/cs-senti/data/amg_cs_final_adjudicated.jsonl\"\n",
        "\n",
        "# Read and preview 10 samples\n",
        "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "    samples = [json.loads(next(f)) for _ in range(10)]\n",
        "\n",
        "for s in samples:\n",
        "    print(f\"ðŸ—£ï¸ Text: {s['text']}\")\n",
        "    print(f\"ðŸŽ¯ Label: {s['label']}\")\n",
        "    print(\"-\"*80)\n"
      ],
      "metadata": {
        "id": "QGvZtzU3b-Z6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NUMBER OF SAMPLES PER DATASETS AND SPLITS; AMG DOESNT HAVE A SPLIT YET"
      ],
      "metadata": {
        "id": "-fL9aCtc6FEg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "BASE = Path(\"/content/drive/MyDrive/cs-senti/data\")\n",
        "\n",
        "def read_jsonl(p):\n",
        "    return [json.loads(l) for l in open(p, encoding=\"utf-8\")]\n",
        "\n",
        "eesa_train = read_jsonl(BASE / \"eesa_train.jsonl\")\n",
        "eesa_dev   = read_jsonl(BASE / \"eesa_dev.jsonl\")\n",
        "eesa_test  = read_jsonl(BASE / \"eesa_test.jsonl\")\n",
        "\n",
        "amg_rows   = read_jsonl(BASE / \"amg_cs_final_adjudicated.jsonl\")\n",
        "\n",
        "print(\"EESA train:\", len(eesa_train))\n",
        "print(\"EESA dev:\", len(eesa_dev))\n",
        "print(\"EESA test:\", len(eesa_test))\n",
        "print(\"AMG CS (final):\", len(amg_rows))\n"
      ],
      "metadata": {
        "id": "WWLNx9R102J2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "AMG SPLIT TRAIN, DEV (TEST?)"
      ],
      "metadata": {
        "id": "dTUKT6Lp6OKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "amg_df = pd.DataFrame(amg_rows)   # has 'text', 'label'\n",
        "\n",
        "amg_train_df, amg_dev_df = train_test_split(\n",
        "    amg_df,\n",
        "    test_size=0.1,\n",
        "    stratify=amg_df[\"label\"],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"AMG train:\", len(amg_train_df))\n",
        "print(\"AMG dev:\", len(amg_dev_df))\n",
        "\n",
        "# (optional) see distribution\n",
        "print(\"\\nAMG train dist:\\n\", amg_train_df[\"label\"].value_counts())\n",
        "print(\"\\nAMG dev dist:\\n\", amg_dev_df[\"label\"].value_counts())\n"
      ],
      "metadata": {
        "id": "1v1sC6Q305vC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MERGING SPLITS"
      ],
      "metadata": {
        "id": "PqT-xe5k6WbI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "OUT_DIR = Path(\"/content/drive/MyDrive/cs-senti/data\")\n",
        "\n",
        "def write_jsonl(path, rows):\n",
        "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for r in rows:\n",
        "            f.write(json.dumps({\"text\": r[\"text\"], \"label\": r[\"label\"]}, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "# merge to train/dev\n",
        "merged_train = eesa_train + amg_train_df.to_dict(orient=\"records\")\n",
        "merged_dev   = eesa_dev   + amg_dev_df.to_dict(orient=\"records\")\n",
        "merged_test  = eesa_test  # unchanged\n",
        "\n",
        "write_jsonl(OUT_DIR / \"eesa_amg_train.jsonl\", merged_train)\n",
        "write_jsonl(OUT_DIR / \"eesa_amg_dev.jsonl\", merged_dev)\n",
        "write_jsonl(OUT_DIR / \"eesa_test.jsonl\", merged_test)\n",
        "\n",
        "print(\"âœ… wrote merged train/dev\")\n",
        "print(\"train:\", len(merged_train), \"dev:\", len(merged_dev), \"test:\", len(merged_test))\n"
      ],
      "metadata": {
        "id": "mNcO6dUR1OuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MERGED STATISTICS OF AMG AND EESA"
      ],
      "metadata": {
        "id": "_JlIjIy26aaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import json, os\n",
        "\n",
        "for name in [\"eesa_amg_train.jsonl\", \"eesa_amg_dev.jsonl\", \"eesa_test.jsonl\"]:\n",
        "    path = OUT_DIR / name\n",
        "    rows = [json.loads(l) for l in open(path, encoding=\"utf-8\")]\n",
        "    cnt = Counter(r[\"label\"] for r in rows)\n",
        "    print(name, \"â†’\", len(rows), \"samples\")\n",
        "    print(cnt)\n",
        "    print(\"-\"*40)\n"
      ],
      "metadata": {
        "id": "EosnRFaf2Skp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LABEL DISTRIBUTION FOR AMG+EESA"
      ],
      "metadata": {
        "id": "zkjw2_lF6hqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "BASE = Path(\"/content/drive/MyDrive/cs-senti/data\")\n",
        "\n",
        "def read_jsonl(p):\n",
        "    return [json.loads(l) for l in open(p, encoding=\"utf-8\")]\n",
        "\n",
        "train_rows = read_jsonl(BASE / \"eesa_amg_train.jsonl\")\n",
        "dev_rows   = read_jsonl(BASE / \"eesa_amg_dev.jsonl\")\n",
        "test_rows  = read_jsonl(BASE / \"eesa_test.jsonl\")\n",
        "\n",
        "print(len(train_rows), len(dev_rows), len(test_rows))\n",
        "print({l: sum(r[\"label\"]==l for r in train_rows) for l in [\"pos\",\"neu\",\"neg\"]})\n"
      ],
      "metadata": {
        "id": "ffZMlRqB4OxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FINE TUNING SENTIMENT CLASSIFIER"
      ],
      "metadata": {
        "id": "uGTlLqDQ6n7P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from torch.optim import AdamW\n",
        "from sklearn.metrics import f1_score\n",
        "from pathlib import Path\n",
        "\n",
        "LABELS = [\"pos\",\"neu\",\"neg\"]  # note the order! match to your data\n",
        "label2id = {l:i for i,l in enumerate(LABELS)}\n",
        "id2label = {i:l for l,i in label2id.items()}\n",
        "\n",
        "class JsonlDS(Dataset):\n",
        "    def __init__(self, data, tok, max_len=128):\n",
        "        self.data = data\n",
        "        self.tok = tok\n",
        "        self.max_len = max_len\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    def __getitem__(self, idx):\n",
        "        ex = self.data[idx]\n",
        "        enc = self.tok(\n",
        "            ex[\"text\"],\n",
        "            max_length=self.max_len,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\"\n",
        "        )\n",
        "        enc[\"labels\"] = label2id[ex[\"label\"]]\n",
        "        return {k: torch.tensor(v) for k,v in enc.items()}\n",
        "\n",
        "# init\n",
        "tok = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"xlm-roberta-base\",\n",
        "    num_labels=3,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ")\n",
        "\n",
        "ds_tr = JsonlDS(train_rows, tok, 128)\n",
        "ds_de = JsonlDS(dev_rows, tok, 128)\n",
        "\n",
        "dl_tr = DataLoader(ds_tr, batch_size=16, shuffle=True)\n",
        "dl_de = DataLoader(ds_de, batch_size=32, shuffle=False)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "optim = AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "best_f1 = -1.0\n",
        "best_state = None\n",
        "\n",
        "EPOCHS = 3\n",
        "for ep in range(1, EPOCHS+1):\n",
        "    model.train()\n",
        "    for batch in dl_tr:\n",
        "        batch = {k:v.to(device) for k,v in batch.items()}\n",
        "        out = model(**batch)\n",
        "        out.loss.backward()\n",
        "        optim.step()\n",
        "        optim.zero_grad()\n",
        "\n",
        "    # dev eval\n",
        "    model.eval()\n",
        "    preds, gold = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in dl_de:\n",
        "            labels = batch[\"labels\"].numpy().tolist()\n",
        "            batch = {k:v.to(device) for k,v in batch.items()}\n",
        "            logits = model(**batch).logits.detach().cpu().numpy()\n",
        "            preds.extend(logits.argmax(axis=1).tolist())\n",
        "            gold.extend(labels)\n",
        "    macro_f1 = f1_score(gold, preds, average=\"macro\")\n",
        "    print(f\"Epoch {ep} â†’ dev macro-F1 = {macro_f1:.4f}\")\n",
        "    if macro_f1 > best_f1:\n",
        "        best_f1 = macro_f1\n",
        "        best_state = model.state_dict()\n",
        "\n",
        "# save best\n",
        "OUT_DIR = Path(\"/content/drive/MyDrive/cs-senti/models/xlmr_sentiment_eesa_amg\")\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "model.load_state_dict(best_state)\n",
        "model.save_pretrained(OUT_DIR.as_posix())\n",
        "tok.save_pretrained(OUT_DIR.as_posix())\n",
        "print(\"âœ… saved best to\", OUT_DIR)\n"
      ],
      "metadata": {
        "id": "XniKQt0V4fGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "LABELS = [\"pos\",\"neu\",\"neg\"]\n",
        "label2id = {l:i for i,l in enumerate(LABELS)}\n",
        "id2label = {i:l for l,i in label2id.items()}\n",
        "\n",
        "DATA_DIR = Path(\"/content/drive/MyDrive/cs-senti/data\")\n",
        "MODEL_DIR = \"/content/drive/MyDrive/cs-senti/models/xlmr_sentiment_eesa_amg\"\n",
        "\n",
        "# load test (same old EESA test)\n",
        "test_rows = [json.loads(l) for l in open(DATA_DIR / \"eesa_test.jsonl\", encoding=\"utf-8\")]\n",
        "\n",
        "class JsonlDS(torch.utils.data.Dataset):\n",
        "    def __init__(self, data, tok, max_len=128):\n",
        "        self.data=data; self.tok=tok; self.max_len=max_len\n",
        "    def __len__(self): return len(self.data)\n",
        "    def __getitem__(self, i):\n",
        "        ex = self.data[i]\n",
        "        enc = self.tok(ex[\"text\"], max_length=self.max_len,\n",
        "                       truncation=True, padding=\"max_length\")\n",
        "        enc[\"labels\"] = label2id[ex[\"label\"]]\n",
        "        return {k: torch.tensor(v) for k,v in enc.items()}\n",
        "\n",
        "tok = AutoTokenizer.from_pretrained(MODEL_DIR)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR).eval().to(\n",
        "    \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        ")\n",
        "\n",
        "ds_te = JsonlDS(test_rows, tok, 128)\n",
        "dl_te = DataLoader(ds_te, batch_size=32, shuffle=False)\n",
        "\n",
        "device = next(model.parameters()).device\n",
        "gold, preds = [], []\n",
        "with torch.no_grad():\n",
        "    for batch in dl_te:\n",
        "        labels = batch[\"labels\"].numpy().tolist()\n",
        "        batch = {k:v.to(device) for k,v in batch.items()}\n",
        "        logits = model(**batch).logits.detach().cpu().numpy()\n",
        "        pred = logits.argmax(axis=1).tolist()\n",
        "        gold.extend(labels); preds.extend(pred)\n",
        "\n",
        "print(\"\\n=== XLM-R (EESA+AMG) on EESA TEST ===\")\n",
        "print(classification_report(gold, preds, target_names=LABELS, digits=4))\n",
        "print(\"Macro-F1:\", f1_score(gold, preds, average=\"macro\"))\n"
      ],
      "metadata": {
        "id": "ZblUpc8o8xzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MR TRI ANNOTATING"
      ],
      "metadata": {
        "id": "QCeZMusf6u6d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json, re, random\n",
        "import pandas as pd\n",
        "\n",
        "MR_FP = \"/content/drive/MyDrive/cs-senti/data/mr_cs.jsonl\"\n",
        "\n",
        "AR = re.compile(r\"[\\u0600-\\u06FF]\")\n",
        "EN = re.compile(r\"[A-Za-z]\")\n",
        "\n",
        "def en_share(s):\n",
        "    toks = re.findall(r\"[A-Za-z\\u0600-\\u06FF]+\", s)\n",
        "    if not toks: return 0.0\n",
        "    en = sum(1 for t in toks if EN.search(t) and not AR.search(t))\n",
        "    return en/len(toks)\n",
        "\n",
        "rows = [json.loads(l) for l in open(MR_FP, encoding=\"utf-8\")]\n",
        "for r in rows:\n",
        "    r[\"en_share\"] = en_share(r[\"text\"])\n",
        "\n",
        "# bucket by en-share\n",
        "low  = [r for r in rows if r[\"en_share\"] < 0.10]\n",
        "mid  = [r for r in rows if 0.10 <= r[\"en_share\"] < 0.22]\n",
        "high = [r for r in rows if r[\"en_share\"] >= 0.22]\n",
        "\n",
        "def sample(lst, k): return random.sample(lst, min(k, len(lst)))\n",
        "\n",
        "sampled = sample(low, 300) + sample(mid, 350) + sample(high, 350)\n",
        "random.shuffle(sampled)\n",
        "\n",
        "mr_sample_df = pd.DataFrame(sampled)\n",
        "mr_sample_df.to_csv(\"/content/drive/MyDrive/cs-senti/data/mr_cs_sample_for_labeling.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "kuDIin3ZMBPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import pandas as pd\n",
        "\n",
        "MODEL_DIR = \"/content/drive/MyDrive/cs-senti/models/xlmr_sentiment_eesa_amg\"\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/cs-senti/data/mr_cs_sample_for_labeling.csv\")\n",
        "\n",
        "tok = AutoTokenizer.from_pretrained(MODEL_DIR)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device).eval()\n",
        "\n",
        "LABELS = [\"pos\",\"neu\",\"neg\"]\n",
        "\n",
        "pred_labels = []\n",
        "pred_confs  = []\n",
        "\n",
        "BATCH = 64\n",
        "texts = df[\"text\"].tolist()\n",
        "for i in range(0, len(texts), BATCH):\n",
        "    batch = texts[i:i+BATCH]\n",
        "    enc = tok(batch, padding=True, truncation=True, max_length=160, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        logits = model(**enc).logits\n",
        "    probs = torch.softmax(logits, dim=-1).cpu().numpy()\n",
        "    labs  = probs.argmax(axis=1)\n",
        "    confs = probs.max(axis=1)\n",
        "    pred_labels.extend([LABELS[j] for j in labs])\n",
        "    pred_confs.extend(confs)\n",
        "\n",
        "df[\"label_model\"] = pred_labels\n",
        "df[\"pred_conf\"]   = pred_confs\n",
        "\n",
        "# save intermediate\n",
        "df.to_csv(\"/content/drive/MyDrive/cs-senti/labeling/mr_cs_sample_with_model.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "print(\"âœ… saved model-labelled MR sample\")\n"
      ],
      "metadata": {
        "id": "H01PPJ9WE-wE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "LABEL_DIR = Path(\"/content/drive/MyDrive/cs-senti/labeling\")\n",
        "LABEL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "df = pd.read_csv(LABEL_DIR / \"mr_cs_sample_with_model.csv\")\n",
        "\n",
        "# give stable ids\n",
        "df = df.reset_index(drop=True)\n",
        "df[\"id\"] = df.index\n",
        "\n",
        "# 1) human file\n",
        "human_path = LABEL_DIR / \"mr_cs_for_human.xlsx\"\n",
        "df[[\"id\",\"text\",\"label_model\",\"pred_conf\",\"en_share\"]].to_excel(human_path, index=False)\n",
        "print(\"âœ… human file:\", human_path)\n",
        "\n",
        "# 2) llm file\n",
        "llm_path = LABEL_DIR / \"mr_cs_for_llm.csv\"\n",
        "df[[\"id\",\"text\"]].to_csv(llm_path, index=False, encoding=\"utf-8-sig\")\n",
        "print(\"âœ… llm file:\", llm_path)\n"
      ],
      "metadata": {
        "id": "Wd5-2ZifFJAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json, pandas as pd, os\n",
        "\n",
        "# path to your text/jsonl file\n",
        "llm_path = \"/content/drive/MyDrive/cs-senti/labeling/mr_cs_llm.txt\"   # or .jsonl if that's the actual name\n",
        "\n",
        "# load each line as json\n",
        "rows = []\n",
        "with open(llm_path, encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        line = line.strip()\n",
        "        if line:\n",
        "            try:\n",
        "                rows.append(json.loads(line))\n",
        "            except json.JSONDecodeError:\n",
        "                print(\"âŒ Skipping malformed line:\", line[:80])\n",
        "\n",
        "llm_df = pd.DataFrame(rows)\n",
        "\n",
        "# keep only id + label\n",
        "if \"label\" in llm_df.columns:\n",
        "    llm_df = llm_df[[\"id\",\"label\"]].rename(columns={\"label\":\"label_llm\"})\n",
        "\n",
        "out_path = \"/content/drive/MyDrive/cs-senti/labeling/mr_cs_llm.csv\"\n",
        "llm_df.to_csv(out_path, index=False, encoding=\"utf-8-sig\")\n",
        "print(f\"âœ… Saved clean LLM labels to {out_path}\")\n",
        "print(llm_df.head())\n"
      ],
      "metadata": {
        "id": "kLbKmTzK04jk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "LABEL_DIR = Path(\"/content/drive/MyDrive/cs-senti/labeling\")\n",
        "\n",
        "model_df = pd.read_excel(LABEL_DIR / \"/content/drive/MyDrive/cs-senti/labeling/mr_cs_for_human.xlsx\")   # id, text, label_model, pred_conf, en_share\n",
        "human_df = pd.read_excel(LABEL_DIR / \"mr_cs_human.xlsx\")            # id, (corrected) label_model\n",
        "llm_df   = pd.read_csv(LABEL_DIR / \"mr_cs_llm.csv\")                 # id, label_llm\n",
        "\n",
        "# make column names consistent\n",
        "human_df = human_df.rename(columns={\"label_model\": \"label_human\"})\n",
        "\n",
        "# merge on id\n",
        "df = (\n",
        "    model_df[[\"id\",\"text\",\"label_model\",\"pred_conf\",\"en_share\"]]\n",
        "    .merge(human_df[[\"id\",\"label_human\"]], on=\"id\")\n",
        "    .merge(llm_df[[\"id\",\"label_llm\"]], on=\"id\")\n",
        ")\n",
        "\n",
        "print(df.head())\n",
        "print(len(df))\n"
      ],
      "metadata": {
        "id": "NEORku3Q5qZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.tail())"
      ],
      "metadata": {
        "id": "B34ewIWP6x6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "pairs = [\n",
        "    (\"label_model\", \"label_human\"),\n",
        "    (\"label_model\", \"label_llm\"),\n",
        "    (\"label_human\", \"label_llm\"),\n",
        "]\n",
        "\n",
        "for a, b in pairs:\n",
        "    kappa = cohen_kappa_score(df[a], df[b])\n",
        "    print(f\"Cohenâ€™s Îº ({a} vs {b}): {kappa:.3f}\")\n",
        "\n",
        "# how many rows had at least 1 disagreement?\n",
        "df[\"n_unique\"] = df[[\"label_model\",\"label_human\",\"label_llm\"]].nunique(axis=1)\n",
        "n_dis = (df[\"n_unique\"] > 1).sum()\n",
        "print(f\"\\nDisagreements: {n_dis} / {len(df)} = {n_dis/len(df)*100:.1f}%\")\n"
      ],
      "metadata": {
        "id": "c4ty_jq-6_rq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "changed_by_human = (df[\"label_model\"] != df[\"label_human\"]).sum()\n",
        "print(\"changed by human:\", changed_by_human, \"/\", len(df),\n",
        "      f\"= {changed_by_human/len(df)*100:.1f}%\")\n",
        "\n",
        "changed_by_llm = (df[\"label_model\"] != df[\"label_llm\"]).sum()\n",
        "print(\"changed by llm:\", changed_by_llm, \"/\", len(df),\n",
        "      f\"= {changed_by_llm/len(df)*100:.1f}%\")\n"
      ],
      "metadata": {
        "id": "TAdoIKWy7F7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def majority_vote(row):\n",
        "    votes = [row[\"label_model\"], row[\"label_human\"], row[\"label_llm\"]]\n",
        "    # simple plurality\n",
        "    return max(set(votes), key=votes.count)\n",
        "\n",
        "df[\"final_label\"] = df.apply(majority_vote, axis=1)\n"
      ],
      "metadata": {
        "id": "JtyYoSNg7NmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) csv\n",
        "final_csv = LABEL_DIR / \"mr_cs_final_adjudicated.csv\"\n",
        "df.to_csv(final_csv, index=False, encoding=\"utf-8-sig\")\n",
        "print(\"âœ… saved:\", final_csv)\n",
        "\n",
        "# 2) jsonl (text + final_label) for training\n",
        "import json\n",
        "final_jsonl = LABEL_DIR / \"mr_cs_final_adjudicated.jsonl\"\n",
        "with open(final_jsonl, \"w\", encoding=\"utf-8\") as f:\n",
        "    for _, row in df.iterrows():\n",
        "        f.write(json.dumps({\"text\": row[\"text\"], \"label\": row[\"final_label\"]}, ensure_ascii=False) + \"\\n\")\n",
        "print(\"âœ… saved:\", final_jsonl)\n"
      ],
      "metadata": {
        "id": "IC-UmV1H7PQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === paths ===\n",
        "BASE = \"/content/drive/MyDrive/cs-senti\"\n",
        "DATA = f\"{BASE}/data\"\n",
        "LABL = f\"{BASE}/labeling\"\n",
        "\n",
        "FP_EESA_TR = f\"{DATA}/eesa_train.jsonl\"\n",
        "FP_EESA_DE = f\"{DATA}/eesa_dev.jsonl\"\n",
        "FP_EESA_TE = f\"{DATA}/eesa_test.jsonl\"\n",
        "\n",
        "FP_AMG     = f\"{DATA}/amg_cs_final_adjudicated.jsonl\"     # text + final_label\n",
        "FP_MR_CSV  = f\"{LABL}/mr_cs_final_adjudicated.csv\"        # needs cleaning\n",
        "\n",
        "# outputs\n",
        "FP_MR_JSON = f\"{DATA}/mr_cs_final_adjudicated.jsonl\"\n",
        "FP_AMG_TR  = f\"{DATA}/amg_train.jsonl\"\n",
        "FP_AMG_DE  = f\"{DATA}/amg_dev.jsonl\"\n",
        "\n",
        "FP_MIX_TR  = f\"{DATA}/eesa_amg_mr_train.jsonl\"\n",
        "FP_MIX_DE  = f\"{DATA}/eesa_amg_mr_dev.jsonl\"\n",
        "FP_MIX_TE  = f\"{DATA}/mixed_test.jsonl\"  # optional cross-domain test\n"
      ],
      "metadata": {
        "id": "FYDrgKHeHwJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd, re, json\n",
        "\n",
        "MIN_ENSHARE = 0.0   # set to 0.05 if you want to filter very low EN-share\n",
        "\n",
        "AR = re.compile(r\"[\\u0600-\\u06FF]\")\n",
        "EN = re.compile(r\"[A-Za-z]\")\n",
        "def en_share(s):\n",
        "    toks = re.findall(r\"[A-Za-z\\u0600-\\u06FF]+\", s or \"\")\n",
        "    if not toks: return 0.0\n",
        "    en = sum(1 for t in toks if EN.search(t) and not AR.search(t))\n",
        "    return en/len(toks)\n",
        "\n",
        "mr = pd.read_csv(FP_MR_CSV)\n",
        "# try common column names defensively\n",
        "text_col = \"text\" if \"text\" in mr.columns else (\"Text\" if \"Text\" in mr.columns else None)\n",
        "assert text_col is not None, f\"Couldn't find a text column in {FP_MR_CSV}\"\n",
        "\n",
        "label_col = \"final_label\" if \"final_label\" in mr.columns else None\n",
        "assert label_col is not None, f\"Couldn't find final_label column in {FP_MR_CSV}\"\n",
        "\n",
        "mr = mr[[ \"id\", text_col, label_col ]].rename(columns={text_col:\"text\", label_col:\"label\"}).dropna(subset=[\"text\",\"label\"])\n",
        "mr[\"en_share\"] = mr[\"text\"].map(en_share)\n",
        "mr = mr[mr[\"en_share\"] >= MIN_ENSHARE].reset_index(drop=True)\n",
        "\n",
        "# write JSONL\n",
        "with open(FP_MR_JSON, \"w\", encoding=\"utf-8\") as f:\n",
        "    for _, row in mr.iterrows():\n",
        "        f.write(json.dumps({\"id\": int(row[\"id\"]), \"text\": row[\"text\"], \"label\": row[\"label\"]}, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "len(mr), mr[\"label\"].value_counts()\n"
      ],
      "metadata": {
        "id": "iP-mrSKWIo9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json, random\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "\n",
        "random.seed(42)\n",
        "\n",
        "def read_jsonl(fp):\n",
        "    with open(fp, encoding=\"utf-8\") as f:\n",
        "        return [json.loads(l) for l in f]\n",
        "\n",
        "def to_df(rows):\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "# --- load sources ---\n",
        "eesa_tr = read_jsonl(FP_EESA_TR)\n",
        "eesa_de = read_jsonl(FP_EESA_DE)\n",
        "eesa_te = read_jsonl(FP_EESA_TE)\n",
        "amg_all = read_jsonl(FP_AMG)       # should have fields: text, final_label/label\n",
        "mr_all  = read_jsonl(FP_MR_JSON)\n",
        "\n",
        "# normalize label key for AMG if needed\n",
        "for r in amg_all:\n",
        "    if \"label\" not in r:\n",
        "        r[\"label\"] = r.get(\"final_label\")\n",
        "for r in amg_all:\n",
        "    r.pop(\"final_label\", None)\n",
        "\n",
        "# stratified 90/10 split for AMG\n",
        "from sklearn.model_selection import train_test_split\n",
        "amg_df = to_df(amg_all)[[\"text\",\"label\"]].dropna()\n",
        "amg_tr_df, amg_de_df = train_test_split(amg_df, test_size=0.10, random_state=42, stratify=amg_df[\"label\"])\n",
        "\n",
        "def write_jsonl(df, fp):\n",
        "    with open(fp, \"w\", encoding=\"utf-8\") as f:\n",
        "        for _, row in df.iterrows():\n",
        "            f.write(json.dumps({\"text\": row[\"text\"], \"label\": row[\"label\"]}, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "write_jsonl(amg_tr_df, FP_AMG_TR)\n",
        "write_jsonl(amg_de_df, FP_AMG_DE)\n",
        "\n",
        "def show_stats(name, rows):\n",
        "    lab = [r[\"label\"] for r in rows]\n",
        "    print(f\"{name} â†’ {len(rows)} samples\")\n",
        "    print(Counter(lab))\n",
        "    print(\"-\"*40)\n",
        "\n",
        "show_stats(\"EESA train\", eesa_tr)\n",
        "show_stats(\"EESA dev\",   eesa_de)\n",
        "show_stats(\"EESA test\",  eesa_te)\n",
        "show_stats(\"AMG train\",  read_jsonl(FP_AMG_TR))\n",
        "show_stats(\"AMG dev\",    read_jsonl(FP_AMG_DE))\n",
        "show_stats(\"MR all (cleaned)\", mr_all[:10])  # just to show it's loaded\n"
      ],
      "metadata": {
        "id": "wZDRhotHI-pc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# re-check FULL MR and all splits (no slicing)\n",
        "from collections import Counter\n",
        "import json, pandas as pd\n",
        "\n",
        "def read_jsonl(fp):\n",
        "    with open(fp, encoding=\"utf-8\") as f:\n",
        "        return [json.loads(l) for l in f]\n",
        "\n",
        "mr_all = read_jsonl(FP_MR_JSON)          # /content/drive/MyDrive/cs-senti/data/mr_cs_final_adjudicated.jsonl\n",
        "amg_tr = read_jsonl(FP_AMG_TR)\n",
        "amg_de = read_jsonl(FP_AMG_DE)\n",
        "\n",
        "print(\"MR all (cleaned) â†’\", len(mr_all), \"samples\")\n",
        "print(Counter([r[\"label\"] for r in mr_all]))\n",
        "print(\"-\"*40)\n",
        "\n",
        "# if you already ran the split cell, re-materialize the MR splits it created:\n",
        "mr_df  = pd.DataFrame(mr_all)[[\"text\",\"label\"]]\n",
        "from sklearn.model_selection import train_test_split\n",
        "mr_tr_df, mr_de_df = train_test_split(mr_df, test_size=0.20, random_state=42, stratify=mr_df[\"label\"])\n",
        "\n",
        "print(\"MR train â†’\", len(mr_tr_df), Counter(mr_tr_df[\"label\"]))\n",
        "print(\"MR dev   â†’\", len(mr_de_df), Counter(mr_de_df[\"label\"]))\n",
        "print(\"-\"*40)\n",
        "\n",
        "print(\"AMG train â†’\", len(amg_tr), Counter([r[\"label\"] for r in amg_tr]))\n",
        "print(\"AMG dev   â†’\", len(amg_de), Counter([r[\"label\"] for r in amg_de]))\n"
      ],
      "metadata": {
        "id": "MZyG57_yKUCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Build mixed train/dev (EESA + AMG + MR) and an optional mixed_test\n",
        "\n",
        "Train = EESA_train + AMG_train + 80% of MR\n",
        "\n",
        "Dev = EESA_dev + AMG_dev + 20% of MR\n",
        "\n",
        "Test (primary) = EESA_test (kept clean for comparability)\n",
        "\n",
        "Test (optional mixed) = small slices from AMG + MR (+ tiny EESA slice if you want)"
      ],
      "metadata": {
        "id": "9FOpnvO3Lqjr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import json, random\n",
        "from collections import Counter\n",
        "\n",
        "# MR split 80/20 stratified\n",
        "mr_df = to_df(mr_all)[[\"text\",\"label\"]].dropna()\n",
        "mr_tr_df, mr_de_df = train_test_split(mr_df, test_size=0.20, random_state=42, stratify=mr_df[\"label\"])\n",
        "\n",
        "# helpers\n",
        "def append_rows(a, b):\n",
        "    out = []\n",
        "    out.extend(a); out.extend(b)\n",
        "    return out\n",
        "\n",
        "# load amg splits just written\n",
        "amg_tr = read_jsonl(FP_AMG_TR)\n",
        "amg_de = read_jsonl(FP_AMG_DE)\n",
        "\n",
        "# build mixed train/dev\n",
        "mix_tr = append_rows(eesa_tr, amg_tr) + [{\"text\":t,\"label\":l} for t,l in zip(mr_tr_df[\"text\"], mr_tr_df[\"label\"])]\n",
        "mix_de = append_rows(eesa_de, amg_de) + [{\"text\":t,\"label\":l} for t,l in zip(mr_de_df[\"text\"], mr_de_df[\"label\"])]\n",
        "\n",
        "# optional small mixed test (10% AMG + 10% MR + 100 EESA)\n",
        "amg_test_slice = amg_de[:max(1, len(amg_de)//2)]\n",
        "mr_test_slice  = [{\"text\":t,\"label\":l} for t,l in zip(mr_de_df[\"text\"], mr_de_df[\"label\"])]\n",
        "eesa_test_slice= eesa_te[:100] if len(eesa_te) > 100 else eesa_te\n",
        "mix_te = amg_test_slice + mr_test_slice + eesa_test_slice\n",
        "\n",
        "# write\n",
        "def write_rows(rows, fp):\n",
        "    with open(fp,\"w\",encoding=\"utf-8\") as f:\n",
        "        for r in rows:\n",
        "            f.write(json.dumps({\"text\": r[\"text\"], \"label\": r[\"label\"]}, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "write_rows(mix_tr, FP_MIX_TR)\n",
        "write_rows(mix_de, FP_MIX_DE)\n",
        "write_rows(mix_te, FP_MIX_TE)\n",
        "\n",
        "print(\"written:\")\n",
        "print(FP_MIX_TR)\n",
        "print(FP_MIX_DE)\n",
        "print(FP_MIX_TE)\n",
        "\n",
        "# show distributions\n",
        "def dist(rows):\n",
        "    return Counter([r[\"label\"] for r in rows])\n",
        "\n",
        "print(\"\\nTRAIN mix:\", len(mix_tr), dist(mix_tr))\n",
        "print(\"DEV   mix:\", len(mix_de), dist(mix_de))\n",
        "print(\"TEST  EESA:\", len(eesa_te), dist(eesa_te))\n",
        "print(\"TEST  mixed:\", len(mix_te), dist(mix_te))\n"
      ],
      "metadata": {
        "id": "H1Q2uB_pLpl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BASE = \"/content/drive/MyDrive/cs-senti\"\n",
        "DATA = f\"{BASE}/data\"\n",
        "\n",
        "FP_MIX_TR = f\"{DATA}/eesa_amg_mr_train.jsonl\"\n",
        "FP_MIX_DE = f\"{DATA}/eesa_amg_mr_dev.jsonl\"\n",
        "FP_MIX_TE = f\"{DATA}/mixed_test.jsonl\"\n",
        "FP_EESA_TE = f\"{DATA}/eesa_test.jsonl\"\n",
        "import json\n",
        "\n",
        "def read_jsonl(fp):\n",
        "    with open(fp, encoding=\"utf-8\") as f:\n",
        "        return [json.loads(l) for l in f]\n",
        "\n",
        "def reorder(rows):\n",
        "    out = []\n",
        "    for r in rows:\n",
        "        lab = r[\"label\"]\n",
        "        if lab in [\"positive\", \"negative\", \"neutral\"]:\n",
        "            lab = {\"positive\": \"pos\", \"negative\": \"neg\", \"neutral\": \"neu\"}[lab]\n",
        "        out.append({\"text\": r[\"text\"], \"label\": lab})\n",
        "    return out\n",
        "tr_rows = reorder(read_jsonl(FP_MIX_TR))\n",
        "de_rows = reorder(read_jsonl(FP_MIX_DE))\n",
        "te_eesa = reorder(read_jsonl(FP_EESA_TE))\n",
        "te_mix  = reorder(read_jsonl(FP_MIX_TE))\n",
        "\n",
        "print(len(tr_rows), \"train\")\n",
        "print(len(de_rows), \"dev\")\n",
        "print(len(te_eesa), \"eesa test\")\n",
        "print(len(te_mix), \"mixed test\")\n"
      ],
      "metadata": {
        "id": "ZzGIth7kQF7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "# ... keep the rest of Cell 7 as-is up to where you build DataLoaders\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tok)  # pads per-batch to longest\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "# num_workers=0 is safer in Colab; you can try 2 later if you want\n",
        "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                      num_workers=0, pin_memory=True, collate_fn=data_collator)\n",
        "dev_dl   = DataLoader(dev_ds,   batch_size=BATCH_SIZE, shuffle=False,\n",
        "                      num_workers=0, pin_memory=True, collate_fn=data_collator)\n",
        "eesa_dl  = DataLoader(eesa_ds,  batch_size=BATCH_SIZE, shuffle=False,\n",
        "                      num_workers=0, pin_memory=True, collate_fn=data_collator)\n",
        "mixed_dl = DataLoader(mixed_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
        "                      num_workers=0, pin_memory=True, collate_fn=data_collator)\n"
      ],
      "metadata": {
        "id": "bBDlfUTUxSKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# replace the scaler line with:\n",
        "scaler = torch.amp.GradScaler('cuda') if torch.cuda.is_available() else None\n",
        "\n",
        "# and wrap the scale/backward/step conditionally\n",
        "def do_backward(loss):\n",
        "    if scaler is not None:\n",
        "        scaler.scale(loss/GRAD_ACCUM).backward()\n",
        "    else:\n",
        "        (loss/GRAD_ACCUM).backward()\n",
        "\n",
        "def do_step():\n",
        "    if scaler is not None:\n",
        "        scaler.step(optim); scaler.update()\n",
        "    else:\n",
        "        optim.step()\n",
        "\n",
        "# inside the train loop:\n",
        "with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
        "    out = model(**batch)\n",
        "    loss = criterion(out.logits, batch[\"labels\"])\n",
        "\n",
        "do_backward(loss)\n",
        "\n",
        "if step % GRAD_ACCUM == 0:\n",
        "    do_step()\n",
        "    optim.zero_grad(set_to_none=True)\n",
        "    scheduler.step()\n"
      ],
      "metadata": {
        "id": "Nngx3qMKxU15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, math, random, numpy as np, torch\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_linear_schedule_with_warmup\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "\n",
        "BASE = \"/content/drive/MyDrive/cs-senti\"\n",
        "DATA = f\"{BASE}/data\"\n",
        "MODELS_DIR = f\"{BASE}/models\"\n",
        "REGISTRY_CSV = f\"{BASE}/runs_sentiment.csv\"\n",
        "os.makedirs(MODELS_DIR, exist_ok=True)\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available(): torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "# load the JSONL prepared in Cell 6\n",
        "def read_jsonl(fp):\n",
        "    with open(fp, encoding=\"utf-8\") as f:\n",
        "        return [json.loads(l) for l in f]\n",
        "\n",
        "train_rows = read_jsonl(f\"{DATA}/eesa_amg_mr_train.jsonl\")\n",
        "dev_rows   = read_jsonl(f\"{DATA}/eesa_amg_mr_dev.jsonl\")\n",
        "test_eesa  = read_jsonl(f\"{DATA}/eesa_test.jsonl\")\n",
        "test_mixed = read_jsonl(f\"{DATA}/mixed_test.jsonl\")\n",
        "\n",
        "label2id = {\"pos\":0, \"neg\":1, \"neu\":2}\n",
        "id2label = {v:k for k,v in label2id.items()}\n",
        "\n",
        "class TxtDS(Dataset):\n",
        "    def __init__(self, rows, tok, max_len=160):\n",
        "        self.rows = rows; self.tok = tok; self.max_len = max_len\n",
        "    def __len__(self): return len(self.rows)\n",
        "    def __getitem__(self, i):\n",
        "        r = self.rows[i]\n",
        "        enc = self.tok(\n",
        "            r[\"text\"],\n",
        "            truncation=True, padding=False, max_length=self.max_len,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        item = {k:v.squeeze(0) for k,v in enc.items()}\n",
        "        item[\"labels\"] = torch.tensor(label2id[r[\"label\"]], dtype=torch.long)\n",
        "        return item\n",
        "\n",
        "MODEL_NAME = \"xlm-roberta-base\"\n",
        "tok = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "train_ds = TxtDS(train_rows, tok)\n",
        "dev_ds   = TxtDS(dev_rows, tok)\n",
        "eesa_ds  = TxtDS(test_eesa, tok)\n",
        "mixed_ds = TxtDS(test_mixed, tok)\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=2, pin_memory=True, collate_fn=None)\n",
        "dev_dl   = DataLoader(dev_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "eesa_dl  = DataLoader(eesa_ds,  batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "mixed_dl = DataLoader(mixed_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "print(\"Train/Dev/Test sizes:\",\n",
        "      len(train_ds), len(dev_ds), len(eesa_ds), len(mixed_ds))\n",
        "\n",
        "# class weights (optional; helps with imbalance)\n",
        "from torch import nn\n",
        "train_counts = Counter(r[\"label\"] for r in train_rows)\n",
        "weights = []\n",
        "for lab in [\"pos\",\"neg\",\"neu\"]:\n",
        "    weights.append(len(train_rows)/max(1, train_counts[lab]))\n",
        "cls_weights = torch.tensor(weights, dtype=torch.float)\n",
        "print(\"Class weights (pos,neg,neu):\", cls_weights.tolist())\n"
      ],
      "metadata": {
        "id": "OQKG3Lqmv2-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=3,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        ").to(device)\n",
        "\n",
        "EPOCHS = 3\n",
        "LR = 2e-5\n",
        "WARMUP_RATIO = 0.06\n",
        "GRAD_ACCUM = 1\n",
        "USE_CLASS_WEIGHTS = True\n",
        "\n",
        "optim = torch.optim.AdamW(model.parameters(), lr=LR)\n",
        "num_update_steps_per_epoch = math.ceil(len(train_dl)/GRAD_ACCUM)\n",
        "t_total = EPOCHS * num_update_steps_per_epoch\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optim,\n",
        "    num_warmup_steps=int(WARMUP_RATIO*t_total),\n",
        "    num_training_steps=t_total\n",
        ")\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=cls_weights.to(device)) if USE_CLASS_WEIGHTS else nn.CrossEntropyLoss()\n",
        "\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n",
        "\n",
        "def evaluate(dl):\n",
        "    model.eval()\n",
        "    all_preds, all_golds = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in dl:\n",
        "            batch = {k:v.to(device) for k,v in batch.items()}\n",
        "            with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
        "                out = model(**batch)\n",
        "            logits = out.logits\n",
        "            preds = logits.argmax(dim=-1).detach().cpu().numpy().tolist()\n",
        "            golds = batch[\"labels\"].detach().cpu().numpy().tolist()\n",
        "            all_preds.extend(preds); all_golds.extend(golds)\n",
        "    macro_f1 = f1_score(all_golds, all_preds, average=\"macro\")\n",
        "    return macro_f1, all_preds, all_golds\n",
        "\n",
        "best_f1 = -1.0\n",
        "best_path = f\"{MODELS_DIR}/xlmr_sentiment_eesa_amg_mr\"\n",
        "history = []\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    model.train()\n",
        "    running = 0.0\n",
        "    optim.zero_grad(set_to_none=True)\n",
        "    pbar = tqdm(train_dl, desc=f\"Epoch {epoch}\")\n",
        "    for step, batch in enumerate(pbar, 1):\n",
        "        batch = {k:v.to(device) for k,v in batch.items()}\n",
        "        with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
        "            out = model(**batch)\n",
        "            loss = criterion(out.logits, batch[\"labels\"])  # override internal loss to inject weights\n",
        "        scaler.scale(loss/GRAD_ACCUM).backward()\n",
        "        running += loss.item()\n",
        "\n",
        "        if step % GRAD_ACCUM == 0:\n",
        "            scaler.step(optim); scaler.update()\n",
        "            optim.zero_grad(set_to_none=True)\n",
        "            scheduler.step()\n",
        "\n",
        "        if step % 50 == 0:\n",
        "            pbar.set_postfix(loss=f\"{running/step:.4f}\")\n",
        "\n",
        "    # dev eval\n",
        "    dev_f1, _, _ = evaluate(dev_dl)\n",
        "    history.append((epoch, dev_f1))\n",
        "    print(f\"Epoch {epoch} â†’ dev macro-F1 = {dev_f1:.4f}\")\n",
        "\n",
        "    if dev_f1 > best_f1:\n",
        "        best_f1 = dev_f1\n",
        "        model.save_pretrained(best_path)\n",
        "        tok.save_pretrained(best_path)\n",
        "        print(f\"âœ… saved best to {best_path}\")\n",
        "\n",
        "print(\"History:\", history)\n",
        "print(\"Best dev macro-F1:\", best_f1)\n"
      ],
      "metadata": {
        "id": "3N3XpYmNwFhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install -U transformers datasets evaluate scikit-learn\n",
        "\n",
        "import os, json, random, numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "BASE = \"/content/drive/MyDrive/cs-senti\"\n",
        "DATA = f\"{BASE}/data\"\n",
        "MODEL_DIR = f\"{BASE}/models/xlmr_sentiment_eesa_amg_mr\"  # where to save\n",
        "\n",
        "FP_MIX_TR = f\"{DATA}/eesa_amg_mr_train.jsonl\"\n",
        "FP_MIX_DE = f\"{DATA}/eesa_amg_mr_dev.jsonl\"\n",
        "FP_EESA_TE = f\"{DATA}/eesa_test.jsonl\"\n",
        "FP_MIX_TE  = f\"{DATA}/mixed_test.jsonl\"\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED)\n"
      ],
      "metadata": {
        "id": "e763jawYypX9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}